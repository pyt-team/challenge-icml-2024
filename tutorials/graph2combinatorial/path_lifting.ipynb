{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2aaa3a1-a8e6-4ecd-bbd5-ecc7b5b72459",
   "metadata": {},
   "source": [
    "# Graph-to-Combinatorial Path Lifting Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf859065-1188-4177-8775-ac58202b88a4",
   "metadata": {},
   "source": [
    "***\n",
    "This notebook shows how to import a dataset, with the desired lifting, and how to run a neural network using the loaded data.\n",
    "\n",
    "The notebook is divided into sections:\n",
    "\n",
    "- [Loading the dataset](#loading-the-dataset) loads the config files for the data and the desired tranformation, createsa a dataset object and visualizes it.\n",
    "- [Loading and applying the lifting](#loading-and-applying-the-lifting) defines a simple neural network to test that the lifting creates the expected incidence matrices.\n",
    "- [Create and run a simplicial nn model](#create-and-run-a-simplicial-nn-model) simply runs a forward pass of the model to check that everything is working as expected.\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "Note that for simplicity the notebook is setup to use a simple graph. However, there is a set of available datasets that you can play with.\n",
    "\n",
    "To switch to one of the available datasets, simply change the *dataset_name* variable in [Dataset config](#dataset-config) to one of the following names:\n",
    "\n",
    "* cocitation_cora\n",
    "* cocitation_citeseer\n",
    "* cocitation_pubmed\n",
    "* MUTAG\n",
    "* NCI1\n",
    "* NCI109\n",
    "* PROTEINS_TU\n",
    "* AQSOL\n",
    "* ZINC\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fe625b-f343-4862-816a-3ae4b9df1ab6",
   "metadata": {},
   "source": [
    "## Imports and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b10b4b7-d6eb-4f94-9d98-556269ff690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this cell any imported module is reloaded before each cell execution\n",
    "from modules.data.load.loaders import GraphLoader\n",
    "from modules.data.preprocess.preprocessor import PreProcessor\n",
    "from modules.utils.utils import (\n",
    "    describe_data,\n",
    "    load_dataset_config,\n",
    "    load_model_config,\n",
    "    load_transform_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181c672c-26dc-4ba1-ab17-178fedfb5388",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78cd57b-6f07-432e-97f1-84f9ca9c9e65",
   "metadata": {},
   "source": [
    "Here we load the `manual_dataset`. First, the dataset config is read from the corresponding yaml file (located at `/configs/datasets/` directory), and then the data is loaded via the implemented `Loaders`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76884cde-0443-4c8f-b268-ecddcfbc6fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"manual_dataset\"\n",
    "dataset_config = load_dataset_config(dataset_name)\n",
    "loader = GraphLoader(dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0512e-3c76-4d20-8c9b-0fbca8f7e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = loader.load()\n",
    "describe_data(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a33549-9d54-4563-8ae6-5789c8881d82",
   "metadata": {},
   "source": [
    "## Loading and Applying the Lifting - Path Lifting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db54f69-dad4-45f0-81ec-94ea6e0623f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation type and id\n",
    "transform_type = \"liftings\"\n",
    "\n",
    "# If the transform is a topological lifting, it should include both the type of the lifting and the identifier\n",
    "transform_id = \"graph2combinatorial/path_lifting\"\n",
    "\n",
    "# Read yaml file\n",
    "transform_config = {\n",
    "    \"lifting\": load_transform_config(transform_type, transform_id)\n",
    "    # other transforms (e.g. data manipulations, feature liftings) can be added here\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bd253c-5845-4893-a74e-de89d67560be",
   "metadata": {},
   "source": [
    "In this section we will instantiate the lifting we want to apply to the data. Since we are lifting graphs to combinatorial complexes (CC), we implemented the path lifting approach from [[1]](https://arxiv.org/abs/2406.04916). We first briefly recall some of the definitions we employed in this notebook from [[2]](https://arxiv.org/abs/2206.00606). Combinatorial complex (CC) constitute a higher-order domain that can be viewed from three perspectives: \n",
    "- as a simplicial complex whose cells and simplices are allowed to be missing;\n",
    "- as a generalized cell complex with relaxed structure;\n",
    "- or as a hypergraph enriched through the inclusion of a rank function.\n",
    "\n",
    "__Definition__ (Neighbourhood function) _Let $S$ be a non-empty set. A neighbourhood function on $S$ is a function $\\mathcal{N}: S \\rightarrow \\mathcal{P}(S)$ that assigns to each point in $x$ in $S$ a non-empty collection $\\mathcal{N}(x)$ of the powerset $\\mathcal{P}(S)$ of $S$. The elements of $\\mathcal{N}(x)$ are called neighbourhoods of $x$ with respect to $\\mathcal{N}$._\n",
    "\n",
    "\n",
    "__Definition__ (Combinatorial complex) _A combinatorial complex (CC) is a triple (S, $\\mathcal{X}$ rk) consisting of a set S, a subset $\\mathcal{X}$ of $\\mathcal{P}(S)\\backslash \\{\\emptyset\\}$, and a function $rk: \\mathcal{X} \\rightarrow \\mathbb{N}$ with the following properties:_\n",
    "\n",
    " - _$\\forall s \\in S, \\{s\\} \\in \\mathcal{X}$_\n",
    " - the function $rk$ is order-preserving, which means that if $x, y \\in \\mathcal{X}$ satisfy $x \\subseteq y$, then $rk(x) \\leq rk(y)$.\n",
    "\n",
    "_The elements of $S$ are called entities or vertices, the elements of $\\mathcal{X}$ are called relations or cells, and $rk$ is called the rank function of the CC. The dimension of a CC is $\\text{dim}(CC) = max(rk(\\mathcal{X}))$ and, for all $r \\in [\\![ 0, \\text{dim}(CC)]\\!]$, we note $\\mathcal{X}_{r}$ the set of all cells or rank $r(\\mathcal{X}_{r} = rk^{-1}(r))$_\n",
    "\n",
    "A lift represents a transformation from a featured domain to another featured domain as thorougly discussed in [[2]](https://arxiv.org/abs/2206.00606), [[3]](https://arxiv.org/abs/2304.10031). For instance, the incorporation of rank-2 cells onto a graph, transforming it into a combinatorial complex, represents a lifting procedure. In [[3]](https://arxiv.org/abs/2304.10031) two lifting procedures are outlined: \n",
    "- the __loop-based__ method;\n",
    "- and the __path-based__ method.\n",
    "\n",
    "We implemented the path-based approach which is defined as [[1]](https://arxiv.org/abs/2406.04916): \n",
    "\n",
    "__Definition__ (Path-based CC of a graph) _Let $\\mathcal{G} = (S, E)$ be a graph. We associate a CC structure with $G$ that considers paths in $G$. The path-based CC of $G$ is denoted by $CC_{P}(G)$ and consists of $0$-cells, $1$-cells and $2$-cells specified as follows. First, one sets $\\mathcal{X}_{0}$ and $\\mathcal{X}_{1}$ in $CC_{P}(G)$ to be nodes and edges of $G$, respectively. A $2$-cell in $CC_{P}(G)$ is constructed as follows. Let $S$ be a set of source nodes and $k\\geq 1$ be the path length. Both of these objects are parameters (see the function `path_based_lift_CC` in `path_lifting.py`)._\n",
    "\n",
    "_Let $P$ be the set of all paths in $G$ starting from a node that belongs to $\\mathcal{S}$ and that has exactly $k$ different nodes. A $2$-cell in $CC_{P}(G)$ is a set $$ C = \\{x_{0}^{1},  \\cdots, x_{0}^{k}\\} \\subset \\mathcal{X}_{0}$$ such that for all $x \\in (\\{x_{0}^{1},  \\cdots, x_{0}^{k}\\})$ there exists a permuation $\\pi_{k}$ such that $\\pi_{k}(x) \\in P$ and such that for all $i \\in [\\![1, k]\\!], (\\pi_{k}(x)_{i}, \\pi_{k}(x)_{i+1 \\, mod \\,k}) \\in \\mathcal{X}$._\n",
    "\n",
    "- We start from the graph representation from the graph in `mutual_dataset`but reproducible for the aforementioned dataset. \n",
    "- We start with one or many source node(s) and a path length $k = 3$.\n",
    "- We identify the nodes belonging to the same paths of length k in the graphs and that start with a node that belongs to the set of source nodes.\n",
    "- We group them together to form a rank-2 cell that is added to create a combinatorial complex (_i.e_: the lifted topology).\n",
    "  \n",
    "***\n",
    "[[1]](https://arxiv.org/abs/2406.04916) Carrel, A. (2024). Combinatorial Complex Score-based Diffusion Modelling through Stochastic Differential Equations (PhD thesis).\n",
    "\n",
    "[[2]](https://arxiv.org/abs/2206.00606) Hajij, M., Zamzmi, G., Papamarkou, T., Miolane, N., Guzmán-Sáenz, A., Ramamurthy, K. N., et al. (2022). Topological deep learning: Going beyond graph data.\n",
    "\n",
    "[[3]](https://arxiv.org/abs/2304.10031) Papillon, M., Sanborn, S., Hajij, M., & Miolane, N. (2023). Architectures of Topological Deep Learning: A Survey on Topological Neural Networks.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb728f8-a809-4a56-932a-81690beecead",
   "metadata": {},
   "source": [
    "We than apply the transform via the `PreProcesor` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1f7d99-8044-4e36-b87b-eedfd5eaab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lifted_dataset = PreProcessor(dataset, transform_config, loader.data_dir)\n",
    "describe_data(lifted_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9848b41a-4b07-4929-ae79-62a5cc112ed4",
   "metadata": {},
   "source": [
    "## Create and Run a Combinatorial NN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4048cfec-18f4-43d5-af3f-c499ee2915b1",
   "metadata": {},
   "source": [
    "In this section a simple model is created to test that the used lifting works as intended. In this case the model uses the `x_0`, `x_1`, `x_2` which are the features of the nodes, edges and cells respectively. It also uses the `adjacency_1`, `incidence_1` and `incidence_2` matrices so the lifting should make sure to add them to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7216b7c3-bdcb-4253-a224-897aa9f88746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.models.combinatorial.hmc import HMCModel\n",
    "\n",
    "model_type = \"combinatorial\"\n",
    "model_id = \"hmc\"\n",
    "model_config = load_model_config(model_type, model_id)\n",
    "model = HMCModel(model_config, dataset_config)\n",
    "\n",
    "y_hat = model(lifted_dataset)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f372490e-d084-4830-a6db-71be97470c85",
   "metadata": {},
   "source": [
    "If everything is correct the cell above should execute without errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
